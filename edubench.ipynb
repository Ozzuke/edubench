{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-10-21T09:18:24.336657Z",
     "start_time": "2025-10-21T09:18:23.646534Z"
    }
   },
   "source": "%pip install autoevals duckdb braintrust openai python-dotenv nest_asyncio --quiet",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m24.3.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m25.2\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-21T09:17:35.393484Z",
     "start_time": "2025-10-21T09:17:35.354095Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "import braintrust\n",
    "from openai import AsyncOpenAI\n",
    "\n",
    "braintrust.login(api_key=os.environ[\"BRAINTRUST_API_KEY\"])\n",
    "client = braintrust.wrap_openai(AsyncOpenAI(api_key=os.environ[\"OPENAI_API_KEY\"]))"
   ],
   "id": "228fd218309884b",
   "outputs": [],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-21T09:17:35.405854Z",
     "start_time": "2025-10-21T09:17:35.402307Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import List, Tuple\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Exchange:\n",
    "    speaker: str  # \"Student\" or \"Teacher\"\n",
    "    message: str\n",
    "\n",
    "@dataclass\n",
    "class StudentTeacherDialog:\n",
    "    background: str\n",
    "    dialog: List[Exchange]\n",
    "\n",
    "sample_dialog = StudentTeacherDialog(\n",
    "    background=\"This is a discussion about the importance of photosynthesis.\",\n",
    "    dialog=[\n",
    "        Exchange(speaker=\"Student\", message=\"I got this problem 'James writes a 3-page letter to 2 different friends twice a week. How many pages does he write a year?' The answer I got is 312. Is it correct?\"),\n",
    "        Exchange(speaker=\"Teacher\", message=\"No, that is not correct. The correct answer is actually 624\"),\n",
    "        Exchange(speaker=\"Student\", message=\"Oh, thx. I will write it down\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "dialogs = [sample_dialog]"
   ],
   "id": "755cb79821f90e00",
   "outputs": [],
   "execution_count": 37
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "a7f746f51e8230b0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-21T09:31:56.420683Z",
     "start_time": "2025-10-21T09:31:56.409333Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "\n",
    "PROMPT = \"\"\"\n",
    "You are comparing a student's answer to a teacher's answer in a dialog. Here is the data:\n",
    "[BEGIN DATA]\n",
    "************\n",
    "[Background]: {background}\n",
    "************\n",
    "{conversation}\n",
    "************\n",
    "[END DATA]\n",
    "\n",
    "Please rate the teacher's effectiveness in teaching the student on a scale of 1 to 10.\n",
    "Provide your answer in the following structured format:\n",
    "Rating: <numeric_rating>\n",
    "Reasoning: <your_reasoning>\n",
    "\"\"\"\n",
    "\n",
    "@braintrust.traced\n",
    "async def numeric_rater(background, conversation):\n",
    "    response = await client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": PROMPT.format(background=background, conversation=conversation),\n",
    "            }\n",
    "        ],\n",
    "        temperature=0,\n",
    "        tools=[\n",
    "            {\n",
    "                \"type\": \"function\",\n",
    "                \"function\": {\n",
    "                    \"name\": \"rate\",\n",
    "                    \"description\": \"Rate the teacher's effectiveness and provide reasoning.\",\n",
    "                    \"parameters\": {\n",
    "                        \"type\": \"object\",\n",
    "                        \"properties\": {\n",
    "                            \"reasons\": {\n",
    "                                \"description\": \"Write out in a step-by-step manner your reasoning to ensure the conclusion is correct.\",\n",
    "                                \"type\": \"string\",\n",
    "                            },\n",
    "                            \"rating\": {\n",
    "                                \"description\": \"The numeric rating on a scale of 1 to 10.\",\n",
    "                                \"type\": \"integer\",\n",
    "                                \"minimum\": 1,\n",
    "                                \"maximum\": 10,\n",
    "                            },\n",
    "                        },\n",
    "                        \"required\": [\"rating\", \"reasons\"],\n",
    "                    },\n",
    "                },\n",
    "            }\n",
    "        ],\n",
    "        tool_choice={\"type\": \"function\", \"function\": {\"name\": \"rate\"}},\n",
    "    )\n",
    "    arguments = json.loads(response.choices[0].message.tool_calls[0].function.arguments)\n",
    "    return {\n",
    "        \"rating\": arguments[\"rating\"],\n",
    "        \"reasoning\": arguments[\"reasons\"]\n",
    "    }\n",
    "\n",
    "async def evaluate_dialogs(dialogs):\n",
    "    results = []\n",
    "    for dialog in dialogs:\n",
    "        conversation = \"\\n\".join(\n",
    "            f\"[{exchange.speaker}]: {exchange.message}\" for exchange in dialog.dialog\n",
    "        )\n",
    "        result = await numeric_rater(dialog.background, conversation)\n",
    "        results.append(result)\n",
    "    return results\n"
   ],
   "id": "22f3422af4ad954a",
   "outputs": [],
   "execution_count": 43
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-21T09:32:05.045056Z",
     "start_time": "2025-10-21T09:32:00.445015Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Run the evaluation\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()\n",
    "results = asyncio.run(evaluate_dialogs(dialogs))\n",
    "\n",
    "# Display the results\n",
    "for result in results:\n",
    "    print(json.dumps(result, indent=2))\n"
   ],
   "id": "d98bf46e90ef04ed",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"rating\": 5,\n",
      "  \"reasoning\": \"The teacher provided the correct answer to the student's question, which is essential for effective teaching. However, the teacher did not explain why the student's answer was incorrect or how to arrive at the correct answer. This lack of explanation means the student may not understand the reasoning behind the correct answer, which is crucial for learning and preventing similar mistakes in the future. Therefore, while the teacher was effective in correcting the student's mistake, the lack of explanation limits the overall effectiveness of the teaching.\"\n",
      "}\n"
     ]
    }
   ],
   "execution_count": 44
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
